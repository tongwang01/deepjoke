{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import cPickle as pickle\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "from lstm_cvae_model import ModelConfig\n",
    "\n",
    "def get_sample_config():\n",
    "    sample_config = {\n",
    "        \"model_dir\": \"/Users/tongwang/Playground/deepjoke/code/model_checkpoints/lstm_cvae/20170618_072219\",\n",
    "        \"starter_sentences\": [\"a sexy\", \"what\", \"why\", \"i have a dream\", \"once upon a time\", \"trump\"],\n",
    "        \"temperatures\": [None, 0.2, 0.5, 1.0, 1.5],\n",
    "        \"scores\": [0, 1, 5, 10, 20],\n",
    "        \"num\": 5\n",
    "    }\n",
    "    return sample_config\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def sample(preds, temperature=None):\n",
    "    \"\"\"Helper function to sample an index from a probability array; if temperature is None, \n",
    "    then sample greedily\"\"\"\n",
    "    if temperature is None:\n",
    "        return np.argmax(preds)\n",
    "    else:\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = softmax(preds)  # Convert logits into probabilities\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def tokens_to_words(tokens, tokenizer, eos=\"\"):\n",
    "    \"\"\"Helper function to turn an 1-d array of tokens tokenized by tokenizer back to words\"\"\"\n",
    "    reverse_word_index = {index: word for word, index in tokenizer.word_index.iteritems()}\n",
    "    reverse_word_index[0] = eos\n",
    "    words = [reverse_word_index.get(token) for token in tokens]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/keras/models.py:258: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/Users/tongwang/Playground/deepjoke/code/model_checkpoints/lstm_cvae/20170618_072219\"\n",
    "encoder_path = model_dir + \"/encoder_checkpoint\"\n",
    "generator_path = model_dir + \"/generator_checkpoint\"\n",
    "tokenizer_path = model_dir + \"/tokenizer.p\"\n",
    "model_config_path = model_dir + \"/model_config.p\"\n",
    "\n",
    "encoder = load_model(encoder_path)\n",
    "generator = load_model(generator_path)\n",
    "tokenizer = pickle.load(open(tokenizer_path, \"r\"))\n",
    "model_config = pickle.load(open(model_config_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_text(target_score, generator, model_config, tokenizer, \n",
    "                  starter_sentence=\"\", temperature=None, variation=1.0, eos=\"\"):\n",
    "    \"\"\"Function to generate paragraphs given a target score, a random latent vector,\n",
    "    and (optionally) a starter sentence.\n",
    "    \n",
    "    Args:\n",
    "        -target_score\n",
    "        -generator\n",
    "        -model_config\n",
    "        -tokenizer\n",
    "        -temperature: if None, generate text greedily; otherwise sample stochastically\n",
    "    Returns:\n",
    "        -model_config.batch_size many pieces of text\n",
    "    \"\"\"\n",
    "    # Prepare inputs\n",
    "    z = np.random.normal(scale=variation., size=(model_config.batch_size, model_config.latent_size))\n",
    "    print(z)\n",
    "    scores = np.repeat(target_score, model_config.batch_size)\n",
    "    cur_sentence = [starter_sentence]\n",
    "    cur_sequence = tokenizer.texts_to_sequences(cur_sentence)\n",
    "    cur_sequence = pad_sequences(cur_sequence, maxlen=model_config.max_sequence_length,\n",
    "                                 padding='post', truncating='post')\n",
    "    cur_sequence = np.repeat(cur_sequence, model_config.batch_size, axis=0)\n",
    "    \n",
    "    reverse_word_index = {index: word for word, index in tokenizer.word_index.iteritems()}\n",
    "\n",
    "    # Iteratively predict the next word\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        true_len = len(cur_sequence[0][cur_sequence[0]>0])\n",
    "        if true_len == model_config.max_sequence_length:\n",
    "            break\n",
    "        next_preds = generator.predict([cur_sequence, scores, z])[0, true_len-1, :] # predicted next word\n",
    "        next_token = sample(next_preds, temperature)\n",
    "        if next_token == 0:\n",
    "            break\n",
    "        cur_sequence[0][true_len] = next_token\"\"\"\n",
    "    while True:\n",
    "        true_lens = np.sum(cur_sequence > 0, axis=1)\n",
    "        last_tokens = np.array([cur_sequence[i, true_lens[i]-1] for i in range(model_config.batch_size)])\n",
    "        print(true_lens)\n",
    "        print(last_tokens)\n",
    "        if np.min(np.logical_or(\n",
    "            (true_lens == model_config.max_sequence_length),\n",
    "            (last_tokens == 0))) > 0:\n",
    "            break\n",
    "        all_preds = generator.predict([cur_sequence, scores, z])\n",
    "        for i in range(model_config.batch_size):\n",
    "            if last_tokens[i] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                next_preds = all_preds[i, true_lens[i]-1, :]\n",
    "                next_token = sample(next_preds, temperature)\n",
    "                cur_sequence[i, true_lens[i]] = next_token\n",
    "\n",
    "    pred_texts = []\n",
    "    for i in range(model_config.batch_size):\n",
    "        pred_sequence = cur_sequence[i][cur_sequence[i]>0]\n",
    "        pred_text = tokens_to_words(pred_sequence, tokenizer=tokenizer, eos=eos)\n",
    "        pred_texts.append(pred_text)\n",
    "    \n",
    "    return pred_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -9.15379304   8.27983002   4.92072988 ...,  -1.42404489 -16.31653623\n",
      "   -6.78862419]\n",
      " [ 11.10850578   4.5269289    3.31255394 ..., -18.58796288 -11.939461\n",
      "   -6.2921765 ]\n",
      " [ -4.67132108   4.68724232   8.91312393 ...,  -1.34071219 -14.39342259\n",
      "    4.81227496]\n",
      " ..., \n",
      " [-19.62167796  -7.77455219  -8.27733414 ...,  16.73833075   8.09323821\n",
      "  -17.93385031]\n",
      " [  6.18136546   7.4858186   -7.84384357 ..., -16.35000095  -3.1640482\n",
      "   -5.57649955]\n",
      " [  7.83658104  -2.37994521 -13.66690602 ...,  -7.76565026   4.85707867\n",
      "    1.38275973]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[  23    4   23   23 1904 1309    8    1 1311   23  101   23   23   23   23\n",
      "  101 1856   23    4 1856   23   23   23   23   23   23    1   23  171   23\n",
      "   23   23]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[ 108 1169   13    5 3681 2276  575 1856    5   13 2531    5   22    3   16\n",
      "    4  434    3 1017    6    3   72   22   22  108  108   11   13  787  108\n",
      "   13  636]\n",
      "[4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "[3016  575    4    4    5   32 1536  434    4   50   22    4    4    1   12\n",
      " 1315    9    4 1030    1    5   13    4    4   56   56    4 1935    5  136\n",
      "   13   16]\n",
      "[5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5]\n",
      "[   5 3300 1856    4 2108    4 1386    6  486    6 3832 1856   23   95    1\n",
      "   17    6    3   22    6    4   32  312  734    4    4    4    6 1169    3\n",
      "   13    4]\n",
      "[6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 5 6 6 6]\n",
      "[ 108 1169    6    4   20 2459 2820    4 1512    1    3  434   12  109 1386\n",
      "    1   27    4    4    1   23    4    4    3 1444  102    4    4 1169 3068\n",
      "   13  238]\n",
      "[7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 6 7 7 7]\n",
      "[3016 1659    6    5   15    4   14    4 2820   95    8   54    1    3    3\n",
      " 1939    9    3  470    6    3  102   23    5   11    5    4 1501   35    3\n",
      "   13   23]\n",
      "[8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 7 8 8 8]\n",
      "[   5    4    6    4 4730 1134    3    4    4 1960   27 1429  102    1    3\n",
      "   17   50    3    5    1    8    5    4    1 1772   70    4    5    4 3068\n",
      "   13   72]\n",
      "[9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 8 9 9 9]\n",
      "[ 873 1169   15    4 4730 3129  575    4  486   13    4    4    1   95    3\n",
      "    1   17    4    4   74    3    4   23  186   11    6    4    4    5    3\n",
      "    6  203]\n",
      "[10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10  9 10 10 10]\n",
      "[3819 1659   15    4 2541 3594 3005    4    4    4 2531 1856  102  109    3\n",
      " 2392    7    3  470    6  726  301   22    2    4    1    4 1117 1169 3068\n",
      "   47  100]\n",
      "[11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11 11\n",
      " 11 11 11 10 11 11 11]\n",
      "[   2    7    6    5  311    7   14    4  486 1856   11   54   12    3    3\n",
      " 2181    8    3    5    1    3    4    4    4  102   23    4    5   12    3\n",
      "    4    2]\n",
      "[12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12\n",
      " 12 12 12 11 12 12 11]\n",
      "[   1 2608    6    4 1939    7 2499    4    5 2718    4    4    1   10    3\n",
      "    1   27    4    4   74    8  301 1400  433   11   22    4   13    4 4245\n",
      "   23    2]\n",
      "[13 13 13 13 12 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13 13\n",
      " 13 13 13 11 13 13 11]\n",
      "[  23 2608    6    4 1939 2289    1    4    4 1675    4  204  102    3    3\n",
      "    4    9    3  470    6    3   12   12    3    4 2240    4 1819    4    1\n",
      "   13    2]\n",
      "[14 14 14 14 12 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14\n",
      " 14 14 14 12 14 14 11]\n",
      "[   3  575   15    4 1939 1599   17    4  486    1    5    2   12   10    3\n",
      "  345   50    3    5    1    8    1    1    5  102    6  486    2    5 2517\n",
      "    1    2]\n",
      "[15 15 15 15 12 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15\n",
      " 15 15 15 13 15 15 11]\n",
      "[   5  797    9    4 1939    7    7    4  717    9    4    4    1    3    3\n",
      "    1   17    3    4   74   16  453   23    4   11   15    4 1819 1169 3812\n",
      "   85    2]\n",
      "[16 16 16 16 12 16 16 16 16 16 16 15 16 16 16 16 16 16 16 16 16 16 16 16 16\n",
      " 16 16 16 14 16 16 11]\n",
      "[  25 3832    3   23 1939    8    1    4   81    9  106    4  102   10    3\n",
      " 2499    7    4  470    6    8   12    1  101    4   15    4    3    2    3\n",
      "    8    2]\n",
      "[17 17 17 17 12 17 17 17 17 17 17 16 17 17 17 17 17 17 17 17 17 17 17 17 17\n",
      " 17 17 17 15 17 17 11]\n",
      "[   3 1659  929    5 1939   52   53    4    4    9    7   23   12    5    3\n",
      " 1568    2    3    5    1   16    1    4  907 3028    4  486 1646    4 3068\n",
      "   36    2]\n",
      "[18 18 18 18 12 18 18 18 18 18 17 17 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 16 18 18 11]\n",
      "[  43   87    3    4 1939 3218   17    4  486    9    7    2    1   10    3\n",
      "    1    9    3    4    1  203  326   23  186   11    4    4    3  241    2\n",
      "    3    2]\n",
      "[19 19 19 19 12 19 19 19 19 19 18 17 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 17 19 19 11]\n",
      "[2751   11   10    4 1939    4    7    1 1498    3    7    2  102   14    3\n",
      " 3005    9   28  470    1   47   12   22    2    4    4  470 1725    3   10\n",
      "    1    2]\n",
      "[20 20 20 20 12 20 20 20 20 20 18 17 20 20 20 20 20 20 20 20 20 20 20 20 20\n",
      " 20 20 20 18 20 20 11]\n",
      "[   3    1 3349    4 1939 2063    1    4    2 1960    7    2    1   10    3\n",
      "    4    7    9    5    1   46    1    4    1 3028    4    1    3  862   25\n",
      "   85    2]\n",
      "[21 21 21 21 13 21 21 21 21 21 18 17 21 21 21 21 21 21 21 21 21 21 21 21 21\n",
      " 21 21 21 18 21 21 11]\n",
      "[   5 4724    3    5    5   73   53    1    1   13    7    2  102    3    3\n",
      "    1    7    3    4    1    4  326   23  186   11  446    4 1819  862    3\n",
      "   23    2]\n",
      "[22 22 22 22 14 22 22 22 22 22 18 18 22 22 22 22 22 22 22 22 22 22 22 22 22\n",
      " 22 22 22 19 22 22 11]\n",
      "[  25    3    9    4 1677 3213   17    4   10    4    7    4   12   14    3\n",
      "   17    7   28  470    1  160    3   22    3  423    2    4    3  154 2392\n",
      "   13    2]\n",
      "[23 23 23 23 15 23 23 23 23 23 18 18 23 23 23 23 23 23 23 23 23 23 23 23 23\n",
      " 23 23 23 20 23 23 11]\n",
      "[   3   11    3    4 3005    4    7    1  821  780    7    4    1    3    3\n",
      "   17    7    9    4    1    3   10    4    5    3    4  902 2772   65    1\n",
      "    2    2]\n",
      "[24 24 24 24 16 24 24 24 24 23 18 18 24 24 24 24 24 24 24 24 24 24 24 24 24\n",
      " 24 24 24 21 24 24 11]\n",
      "[  43    4    9    4 3016 1041    1    4    1  780    7    4  102   10    3\n",
      "   10    7   28  470    1    5  159  275   10    1   23    4    6    5 3498\n",
      "    1    2]\n",
      "[25 25 25 25 17 25 25 25 25 24 18 18 25 25 25 25 25 25 25 25 25 25 25 25 25\n",
      " 25 25 25 22 25 25 11]\n",
      "[   3    4    3   20 3736 1611    3    1  821    1    7    4    1   16    3\n",
      "    4    2 1236    5    1    8    1    5 1506   73    5 1169 3736   25    3\n",
      "   85    2]\n",
      "[26 26 26 26 18 26 26 26 26 25 18 18 26 26 26 26 26 26 26 26 26 26 26 26 26\n",
      " 26 26 26 23 26 26 11]\n",
      "[  43 1199    9    4    1    6   17    4    1    9    7    4  102   10    9\n",
      "  295  190   66    4    1   16  912   14    3   11    4    5 1819    6 3144\n",
      "   23    2]\n",
      "[27 27 27 27 19 27 27 27 27 26 18 18 27 27 27 27 27 27 27 27 27 27 27 27 27\n",
      " 27 27 27 24 27 27 11]\n",
      "[   3 4187    3    5 3012    4    7    1  286    1    7    4   12    3    3\n",
      "    6   17    3  470    1    8    3   10    5    1   23    1   49    1    3\n",
      "   13    2]\n",
      "[28 28 28 28 20 28 28 28 28 27 18 18 28 28 28 28 28 28 28 28 28 28 28 28 28\n",
      " 28 28 28 24 28 28 12]\n",
      "[  43 2608    9    4 3736 1041    1    1    5    9    7    4    1   14    6\n",
      "   27    7   28    5    1   16    1   16    4  102   72    1 4355    1 2531\n",
      " 2063    8]\n",
      "[29 29 29 29 21 29 29 29 29 28 18 18 29 29 29 29 29 29 29 29 29 29 29 29 29\n",
      " 29 29 29 25 29 29 13]\n",
      "[   3 1199    3    4 4730 2104   10    1  904    9    7    4  102    2    3\n",
      "    4    2    9    4    1  203   23    4  632   11   16    4    3   65   10\n",
      "    3   16]\n",
      "[30 30 30 30 22 30 30 30 30 29 18 18 30 30 30 30 30 30 30 30 30 30 30 30 30\n",
      " 30 30 30 26 30 30 14]\n",
      "[   5 4187    9    4 2791 4349    7    1   14    9    7    4   12   10    6\n",
      "    1  600   66  470    1   47   72   23    2    1 2499    4 1819    3   25\n",
      "    1   12]\n",
      "[31 31 31 31 22 31 31 31 31 30 18 18 31 31 31 31 31 31 31 31 31 31 31 31 31\n",
      " 31 31 31 27 31 31 15]\n",
      "[  43 1199    3    5 2791 1646    1    1    4    9    7    4    1   14    3\n",
      "  382    2    3    5    1   55    7  877    4  102    2    4    3    5    3\n",
      "   85    4]\n",
      "[32 32 32 32 22 32 32 32 32 31 18 18 32 32 32 32 32 32 32 32 32 32 32 32 32\n",
      " 32 32 32 28 32 32 16]\n",
      "[2838 4187    7    4 2791    4   10    1  486    9    7    4  102    2    3\n",
      "   17  600   28    4    1    8    1    3  101   11    4  810 3832 4563 2392\n",
      "   33   87]\n",
      "[33 33 33 33 22 33 33 33 33 32 18 18 33 33 33 33 33 33 33 33 33 33 33 33 33\n",
      " 33 33 33 29 33 33 17]\n",
      "[3819 1199    3    4 2791 1599 3870    1  138   13    7    4   12   10    3\n",
      "   17  116    9  470    1    8  326    5 1151    1   23    4    3  154    1\n",
      "    8    2]\n",
      "[34 34 34 34 22 34 34 34 34 33 18 18 34 34 34 34 34 34 34 34 34 34 34 34 34\n",
      " 34 34 34 30 34 34 18]\n",
      "[   2 4187 3678    4 2791    7   17 1386 3153 1752    7    4    1    3    3\n",
      "    4   17    9    5    1  203    5    1    3  102    5    4 1819   35 3498\n",
      "   92    8]\n",
      "[35 35 35 35 22 35 35 35 35 33 18 18 35 35 35 35 35 35 35 35 35 35 35 35 35\n",
      " 35 35 35 31 35 35 19]\n",
      "[  26 1199    3    4 2791    8    9    3    1 1752    7    4  102   14    3\n",
      "  345    7    1    4    1  203   43   23    5   11    4  190    3    5    3\n",
      " 2727    8]\n",
      "[36 36 36 36 22 36 36 36 36 33 18 18 36 36 36 36 35 36 36 36 36 36 36 36 36\n",
      " 36 36 36 32 36 36 20]\n",
      "[   3 4187 1797   23 2791   50   17    1  286 1752    7    4    1    2    3\n",
      "    1    7 2608  470    1  203    9    1    4    1   98   11 2772   25 3678\n",
      "    1   16]\n",
      "[37 37 37 37 22 37 37 37 37 33 18 18 37 37 37 37 36 37 37 37 37 37 37 37 37\n",
      " 37 37 37 33 37 37 21]\n",
      "[  43 1199    3    5 2791    8    7    1    2 1752    7    4  102   10    3\n",
      " 3005    2 3005   12    1  203    4   23  101  102   72    1    6    3    3\n",
      " 1646   12]\n",
      "[38 38 38 38 22 38 38 38 38 33 18 18 38 38 38 38 37 38 38 38 38 38 38 38 38\n",
      " 38 38 38 34 38 38 22]\n",
      "[   3 4187    9    4 2791 2499    1 1386   14 1752    7    4   12    3    9\n",
      "   14  600    3    4    1  203   98   10  907   11   16    4 3736 1169 3068\n",
      "    2    1]\n",
      "[39 39 39 39 22 39 39 39 39 34 18 18 39 39 39 39 38 39 39 39 39 39 39 39 39\n",
      " 39 39 39 34 39 39 23]\n",
      "[  43 1199    3    4 2791    4   10    3  840   13    7    4    1   14    3\n",
      "    1  116   28  470    1  203   72   16    3    1 3190    1 1819 1169    3\n",
      "    1   87]\n",
      "[40 40 40 40 22 40 40 40 40 35 18 18 40 40 40 40 39 40 40 40 40 40 40 40 40\n",
      " 40 40 40 35 40 40 24]\n",
      "[1921 4187    9   23 2791 1041    7    1    6    6    7    4  102    3    3\n",
      " 3005   36   28    5    1  203   12    1    5   11    6    1   49    5 3068\n",
      "   85    8]\n",
      "[41 41 41 41 22 41 41 41 41 36 18 18 41 41 41 41 40 41 41 41 41 41 41 41 41\n",
      " 41 41 41 36 41 41 25]\n",
      "[4730 1900    3    5 2791 1041   10    1    1    6    7    4    3   10   10\n",
      "    4    7   28    4    1  203    4    1    1    4   15    1 1117 2347    3\n",
      "    3    8]\n",
      "[42 42 42 42 22 42 42 42 42 37 18 18 42 42 42 42 41 42 42 42 42 42 42 42 42\n",
      " 42 42 42 36 42 42 26]\n",
      "[   3    4    3    4 2791 1646    7 1386  821    9    7    4   33    3   13\n",
      "  295    2  222  470    1  203  129   23  186  102  144    1    3 2347 3068\n",
      "    1    8]\n",
      "[43 43 43 43 22 43 43 43 43 38 18 18 43 43 43 43 42 43 43 43 43 43 43 43 43\n",
      " 43 43 43 36 43 43 27]\n",
      "[  26    4 2896    4 2791 1646   10    3    1    9    7    4   11   14    2\n",
      "    7    2    1    5    1  203  313    1    3   11   11    1 2426 2347    3\n",
      "   85    8]\n",
      "[44 44 44 44 22 44 44 44 44 39 18 18 44 44 44 44 43 44 44 44 44 44 44 44 44\n",
      " 44 44 44 36 44 44 28]\n",
      "[   3    4    3    4 2791 3045    7    1    1    7    7    4    1   10    6\n",
      "    4  600 1646    4    1  203    2    1    9    1  575    1   13 2347 4245\n",
      "    3   16]\n",
      "[45 45 45 45 22 45 45 45 45 40 18 18 45 45 45 45 44 45 45 45 45 45 45 45 45\n",
      " 45 45 45 36 45 45 29]\n",
      "[2995    4    9    5 2791    7   53    1 1838    9    7    4  102   10    3\n",
      "  382  116  140  470    1   47    1   23    4   23    2    1 3832 2347    3\n",
      "    1   12]\n",
      "[46 46 46 46 22 46 46 46 46 41 18 18 46 46 46 46 45 46 46 46 46 46 46 46 46\n",
      " 46 46 46 36 46 46 30]\n",
      "[2953    4    3    4 2791    8   53    1    4    9    7    4   12    2    6\n",
      "    7   17    3    5    1   72   23    1  377   11    4    1    3 2347 3068\n",
      "   85    1]\n",
      "[47 47 47 47 22 47 47 47 47 42 18 18 47 47 47 47 46 47 47 47 47 47 47 47 47\n",
      " 47 47 47 36 47 47 31]\n",
      "[ 622    4 1659    4 2791   50   53    1 1756 1676    7    4    1   10    3\n",
      "    1    7    1    4    1 3812  159    1   38    1   23    1 1819 2347    3\n",
      "    3  186]\n",
      "[48 48 48 48 22 48 48 48 48 43 18 18 48 48 48 48 46 48 48 48 47 48 48 48 48\n",
      " 48 48 48 36 48 48 31]\n",
      "[   3    4    7    4 2791   36   53    1    2   13    7    4  102    2    3\n",
      " 3005    7    1  470    1 3812    1   23   11   11   72    1    3 2347 3068\n",
      "    1  186]\n",
      "[49 49 49 49 22 49 49 49 49 44 18 18 49 49 49 49 47 49 49 49 47 49 49 49 49\n",
      " 49 49 49 36 49 49 32]\n",
      "[  19    4    3   20 2791    9   53    1    1    1    7    4   12   10    3\n",
      "   14    7    3    5    1 3812  463   72    1   11   16    1 3886 2347    3\n",
      "   85    8]\n",
      "[50 50 50 50 22 50 50 50 50 45 18 18 50 50 50 50 48 50 50 50 47 50 50 50 50\n",
      " 50 50 50 36 50 50 33]\n",
      "[2995    4 1184    4 2791 2499   53    1    1 1659    7    4    1    3    3\n",
      "   16    2 3005    4    1 3812    2   16  186   11 2499    1    2 2347 3068\n",
      "    3   16]\n",
      "[51 51 51 51 22 51 51 51 51 46 18 18 51 51 51 51 49 51 51 51 48 51 51 51 51\n",
      " 51 51 51 36 51 51 34]\n",
      "[2995    4    3    5 2791    4   53    1  286    9    7    4  102   14    3\n",
      "    4    2    1  470    1    3    1    1    2    4    5    1 1819 2347    3\n",
      "    1   12]\n",
      "[52 52 52 52 22 52 52 52 52 47 18 18 52 52 52 52 50 52 52 52 49 52 52 52 52\n",
      " 52 52 52 36 52 52 35]\n",
      "[2995    4 1184    1 2791 1041   53    1   10    9    7    4   12    3    9\n",
      "  345  600 1646    5    1    8   23   23    4 1775    4    1    3 2347 4245\n",
      "   85    1]\n",
      "[53 53 53 53 22 53 53 53 53 48 18 18 53 53 53 53 51 53 53 53 50 53 53 53 53\n",
      " 53 53 53 36 53 53 36]\n",
      "[2995    4    3    4 2791    8   53    1 1207    9    7    4    1   10    3\n",
      "    2    2    1    4    1   16   43  345  190   23   23    1 1646 2347    3\n",
      "   33  186]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-652bae3420d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m s = generate_text(generator=generator, model_config=model_config, tokenizer=tokenizer,\n\u001b[0;32m----> 2\u001b[0;31m               target_score=2, starter_sentence=\"a\", variation=3.0, temperature=0.2)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-0c237132c22e>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(target_score, generator, model_config, tokenizer, starter_sentence, temperature, variation, eos)\u001b[0m\n\u001b[1;32m     45\u001b[0m             (last_tokens == 0))) > 0:\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1592\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1594\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1218\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2267\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2268\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2269\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = generate_text(generator=generator, model_config=model_config, tokenizer=tokenizer,\n",
    "              target_score=2, starter_sentence=\"a\", variation=3.0, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.random.normal(size=(5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68480836,  0.34998149,  0.38515765, -0.41151523],\n",
       "       [ 1.52700636,  0.66575251,  0.31049105,  0.18926559],\n",
       "       [ 0.93849434,  0.55826684, -0.61776509,  0.21317279],\n",
       "       [-0.37012515, -1.25836485,  0.45113172,  0.88775646],\n",
       "       [-0.03215376, -0.3352601 ,  0.82262767, -0.28751208]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
