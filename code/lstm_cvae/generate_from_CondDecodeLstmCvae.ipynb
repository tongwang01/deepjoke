{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import cPickle as pickle\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from data_generator import DataGenerator\n",
    "from lstm_cvae_model import ModelConfig\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/keras/models.py:258: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# Load trained models\n",
    "\n",
    "MODEL_DIR = \"/Users/tongwang/Playground/deepjoke/code/model_checkpoints/lstm_cvae/20170618_072219\"\n",
    "encoder_path = MODEL_DIR + \"/encoder_checkpoint\"\n",
    "generator_path = MODEL_DIR + \"/generator_checkpoint\"\n",
    "tokenizer_path = MODEL_DIR + \"/tokenizer.p\"\n",
    "model_config_path = MODEL_DIR + \"/model_config.p\"\n",
    "\n",
    "encoder = load_model(encoder_path)\n",
    "generator = load_model(generator_path)\n",
    "tokenizer = pickle.load(open(tokenizer_path, \"r\"))\n",
    "model_config = pickle.load(open(model_config_path, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def sample(preds, temperature=None):\n",
    "    \"\"\"Helper function to sample an index from a probability array; if temperature is None, \n",
    "    then sample greedily\"\"\"\n",
    "    if temperature is None:\n",
    "        return np.argmax(preds)\n",
    "    else:\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = softmax(preds)  # Convert logits into probabilities\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def tokens_to_words(tokens, tokenizer, eos=\"\"):\n",
    "    \"\"\"Helper function to turn an 1-d array of tokens tokenized by tokenizer back to words\"\"\"\n",
    "    reverse_word_index = {index: word for word, index in tokenizer.word_index.iteritems()}\n",
    "    reverse_word_index[0] = eos\n",
    "    words = [reverse_word_index.get(token) for token in tokens]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_text(target_score, generator, model_config, tokenizer,\n",
    "                  starter_sentence=\"\", temperature=None, eos=\"\"):\n",
    "    \"\"\"Function to generate paragraphs given a target score, a random latent vector,\n",
    "    and (optionally) a starter sentence.\n",
    "    \n",
    "    Args:\n",
    "        -target_score\n",
    "        -generator\n",
    "        -model_config\n",
    "        -tokenizer\n",
    "        -temperature: if None, generate text greedily; otherwise sample stochastically\n",
    "    Returns:\n",
    "        -model_config.batch_size many pieces of text\n",
    "    \"\"\"\n",
    "    # Prepare inputs\n",
    "    z = np.random.normal(size=(model_config.batch_size, model_config.latent_size))\n",
    "    scores = np.repeat(target_score, model_config.batch_size)\n",
    "    cur_sentence = [starter_sentence]\n",
    "    cur_sequence = tokenizer.texts_to_sequences(cur_sentence)\n",
    "    cur_sequence = pad_sequences(cur_sequence, maxlen=model_config.max_sequence_length,\n",
    "                                 padding='post', truncating='post')\n",
    "    cur_sequence = np.repeat(cur_sequence, model_config.batch_size, axis=0)\n",
    "    \n",
    "    reverse_word_index = {index: word for word, index in tokenizer.word_index.iteritems()}\n",
    "    # Iteratively predict the next word\n",
    "    while True:\n",
    "        true_len = len(cur_sequence[0][cur_sequence[0]>0])\n",
    "        if true_len == model_config.max_sequence_length:\n",
    "            break\n",
    "        next_preds = generator.predict([cur_sequence, scores, z])[0, true_len-1, :] # predicted next word\n",
    "        next_token = sample(next_preds, temperature)\n",
    "        if next_token == 0:\n",
    "            break\n",
    "        cur_sequence[0][true_len] = next_token\n",
    "        print(\"current sentence length: {}, \\\n",
    "        new token: {}\".format(true_len, reverse_word_index.get(next_token)))\n",
    "    pred_sequence = cur_sequence[0][cur_sequence[0]>0]\n",
    "      \n",
    "    # Translate tokens to words\n",
    "    pred_text = tokens_to_words(pred_sequence, tokenizer=tokenizer, eos=eos)\n",
    "    \n",
    "    return pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sentence length: 2,         new token: walks\n",
      "current sentence length: 3,         new token: into\n",
      "current sentence length: 4,         new token: a\n",
      "current sentence length: 5,         new token: bar\n",
      "current sentence length: 6,         new token: and\n",
      "current sentence length: 7,         new token: sees\n",
      "current sentence length: 8,         new token: a\n",
      "current sentence length: 9,         new token: man\n",
      "current sentence length: 10,         new token: sitting\n",
      "current sentence length: 11,         new token: next\n",
      "current sentence length: 12,         new token: to\n",
      "current sentence length: 13,         new token: him\n",
      "current sentence length: 14,         new token: .\n",
      "current sentence length: 15,         new token: he\n",
      "current sentence length: 16,         new token: says\n",
      "current sentence length: 17,         new token: ,\n",
      "current sentence length: 18,         new token: i\n",
      "current sentence length: 19,         new token: have\n",
      "current sentence length: 20,         new token: a\n",
      "current sentence length: 21,         new token: problem\n",
      "current sentence length: 22,         new token: with\n",
      "current sentence length: 23,         new token: my\n",
      "current sentence length: 24,         new token: wife\n",
      "current sentence length: 25,         new token: .\n",
      "current sentence length: 26,         new token: i\n",
      "current sentence length: 27,         new token: don't\n",
      "current sentence length: 28,         new token: know\n",
      "current sentence length: 29,         new token: what\n",
      "current sentence length: 30,         new token: he\n",
      "current sentence length: 31,         new token: wants\n",
      "current sentence length: 32,         new token: .\n",
      "current sentence length: 33,         new token: the\n",
      "current sentence length: 34,         new token: man\n",
      "current sentence length: 35,         new token: says\n",
      "current sentence length: 36,         new token: ,\n",
      "current sentence length: 37,         new token: i\n",
      "current sentence length: 38,         new token: don't\n",
      "current sentence length: 39,         new token: know\n",
      "current sentence length: 40,         new token: ,\n",
      "current sentence length: 41,         new token: i\n",
      "current sentence length: 42,         new token: have\n",
      "current sentence length: 43,         new token: to\n",
      "current sentence length: 44,         new token: tell\n",
      "current sentence length: 45,         new token: you\n",
      "current sentence length: 46,         new token: that\n",
      "current sentence length: 47,         new token: i\n",
      "current sentence length: 48,         new token: have\n",
      "current sentence length: 49,         new token: a\n",
      "current sentence length: 50,         new token: problem\n",
      "current sentence length: 51,         new token: with\n",
      "current sentence length: 52,         new token: my\n",
      "current sentence length: 53,         new token: penis\n",
      "current sentence length: 54,         new token: .\n",
      "current sentence length: 55,         new token: i\n",
      "current sentence length: 56,         new token: don't\n",
      "current sentence length: 57,         new token: know\n",
      "current sentence length: 58,         new token: ,\n",
      "current sentence length: 59,         new token: i\n",
      "current sentence length: 60,         new token: don't\n",
      "current sentence length: 61,         new token: know\n",
      "current sentence length: 62,         new token: ,\n",
      "current sentence length: 63,         new token: i\n",
      "current sentence length: 64,         new token: don't\n",
      "current sentence length: 65,         new token: know\n",
      "current sentence length: 66,         new token: ,\n",
      "current sentence length: 67,         new token: i\n",
      "current sentence length: 68,         new token: don't\n",
      "current sentence length: 69,         new token: know\n",
      "current sentence length: 70,         new token: ,\n",
      "current sentence length: 71,         new token: i\n",
      "current sentence length: 72,         new token: don't\n",
      "current sentence length: 73,         new token: know\n",
      "current sentence length: 74,         new token: ,\n",
      "current sentence length: 75,         new token: i\n",
      "current sentence length: 76,         new token: don't\n",
      "current sentence length: 77,         new token: know\n",
      "current sentence length: 78,         new token: ,\n",
      "current sentence length: 79,         new token: i\n",
      "current sentence length: 80,         new token: don't\n",
      "current sentence length: 81,         new token: know\n",
      "current sentence length: 82,         new token: ,\n",
      "current sentence length: 83,         new token: i\n",
      "current sentence length: 84,         new token: don't\n",
      "current sentence length: 85,         new token: know\n",
      "current sentence length: 86,         new token: ,\n",
      "current sentence length: 87,         new token: i\n",
      "current sentence length: 88,         new token: don't\n",
      "current sentence length: 89,         new token: know\n",
      "current sentence length: 90,         new token: ,\n",
      "current sentence length: 91,         new token: i\n",
      "current sentence length: 92,         new token: don't\n",
      "current sentence length: 93,         new token: know\n",
      "current sentence length: 94,         new token: ,\n",
      "current sentence length: 95,         new token: i\n",
      "current sentence length: 96,         new token: don't\n",
      "current sentence length: 97,         new token: know\n",
      "current sentence length: 98,         new token: ,\n",
      "current sentence length: 99,         new token: i\n",
      "current sentence length: 100,         new token: don't\n",
      "current sentence length: 101,         new token: know\n",
      "current sentence length: 102,         new token: ,\n",
      "current sentence length: 103,         new token: i\n",
      "current sentence length: 104,         new token: don't\n",
      "current sentence length: 105,         new token: know\n",
      "current sentence length: 106,         new token: ,\n",
      "current sentence length: 107,         new token: i\n",
      "current sentence length: 108,         new token: don't\n",
      "current sentence length: 109,         new token: know\n",
      "current sentence length: 110,         new token: ,\n",
      "current sentence length: 111,         new token: i\n",
      "current sentence length: 112,         new token: don't\n",
      "current sentence length: 113,         new token: know\n",
      "current sentence length: 114,         new token: ,\n",
      "current sentence length: 115,         new token: i\n",
      "current sentence length: 116,         new token: don't\n",
      "current sentence length: 117,         new token: know\n",
      "current sentence length: 118,         new token: ,\n",
      "current sentence length: 119,         new token: i\n",
      "current sentence length: 120,         new token: don't\n",
      "current sentence length: 121,         new token: know\n",
      "current sentence length: 122,         new token: ,\n",
      "current sentence length: 123,         new token: i\n",
      "current sentence length: 124,         new token: don't\n",
      "current sentence length: 125,         new token: know\n",
      "current sentence length: 126,         new token: ,\n",
      "current sentence length: 127,         new token: i\n",
      "current sentence length: 128,         new token: don't\n",
      "current sentence length: 129,         new token: know\n",
      "current sentence length: 130,         new token: ,\n",
      "current sentence length: 131,         new token: i\n",
      "current sentence length: 132,         new token: don't\n",
      "current sentence length: 133,         new token: know\n",
      "current sentence length: 134,         new token: ,\n",
      "current sentence length: 135,         new token: i\n",
      "current sentence length: 136,         new token: don't\n",
      "current sentence length: 137,         new token: know\n",
      "current sentence length: 138,         new token: ,\n",
      "current sentence length: 139,         new token: i\n",
      "current sentence length: 140,         new token: don't\n",
      "current sentence length: 141,         new token: know\n",
      "current sentence length: 142,         new token: ,\n",
      "current sentence length: 143,         new token: i\n",
      "current sentence length: 144,         new token: don't\n",
      "current sentence length: 145,         new token: know\n",
      "current sentence length: 146,         new token: ,\n",
      "current sentence length: 147,         new token: i\n",
      "current sentence length: 148,         new token: don't\n",
      "current sentence length: 149,         new token: know\n",
      "current sentence length: 150,         new token: ,\n",
      "current sentence length: 151,         new token: i\n",
      "current sentence length: 152,         new token: don't\n",
      "current sentence length: 153,         new token: know\n",
      "current sentence length: 154,         new token: ,\n",
      "current sentence length: 155,         new token: i\n",
      "current sentence length: 156,         new token: don't\n",
      "current sentence length: 157,         new token: know\n",
      "current sentence length: 158,         new token: ,\n",
      "current sentence length: 159,         new token: i\n",
      "current sentence length: 160,         new token: don't\n",
      "current sentence length: 161,         new token: know\n",
      "current sentence length: 162,         new token: ,\n",
      "current sentence length: 163,         new token: i\n",
      "current sentence length: 164,         new token: don't\n",
      "current sentence length: 165,         new token: know\n",
      "current sentence length: 166,         new token: ,\n",
      "current sentence length: 167,         new token: i\n",
      "current sentence length: 168,         new token: don't\n",
      "current sentence length: 169,         new token: know\n",
      "current sentence length: 170,         new token: ,\n",
      "current sentence length: 171,         new token: i\n",
      "current sentence length: 172,         new token: don't\n",
      "current sentence length: 173,         new token: know\n",
      "current sentence length: 174,         new token: ,\n",
      "current sentence length: 175,         new token: i\n",
      "current sentence length: 176,         new token: don't\n",
      "current sentence length: 177,         new token: know\n",
      "current sentence length: 178,         new token: ,\n",
      "current sentence length: 179,         new token: i\n",
      "current sentence length: 180,         new token: don't\n",
      "current sentence length: 181,         new token: know\n",
      "current sentence length: 182,         new token: ,\n",
      "current sentence length: 183,         new token: i\n",
      "current sentence length: 184,         new token: don't\n",
      "current sentence length: 185,         new token: know\n",
      "current sentence length: 186,         new token: ,\n",
      "current sentence length: 187,         new token: i\n",
      "current sentence length: 188,         new token: don't\n",
      "current sentence length: 189,         new token: know\n",
      "current sentence length: 190,         new token: ,\n",
      "current sentence length: 191,         new token: but\n",
      "current sentence length: 192,         new token: i\n",
      "current sentence length: 193,         new token: don't\n",
      "current sentence length: 194,         new token: know\n",
      "current sentence length: 195,         new token: what\n",
      "current sentence length: 196,         new token: i\n",
      "current sentence length: 197,         new token: mean\n",
      "current sentence length: 198,         new token: .\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6ff27bb2f01a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m text = generate_text(target_score=5, generator=generator, model_config=model_config,\n\u001b[1;32m      4\u001b[0m                     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarter_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTARTER_SENTENCE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     temperature=None)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e945c5584ee5>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(target_score, generator, model_config, tokenizer, starter_sentence, temperature, eos)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mpred_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens_to_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: global name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "STARTER_SENTENCE=\"a man\"\n",
    "\n",
    "text1 = generate_text(target_score=5, generator=generator, model_config=model_config,\n",
    "                    tokenizer=tokenizer, starter_sentence=STARTER_SENTENCE,\n",
    "                    temperature=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sentence length: 2,         new token: walks\n",
      "current sentence length: 3,         new token: into\n",
      "current sentence length: 4,         new token: a\n",
      "current sentence length: 5,         new token: bar\n",
      "current sentence length: 6,         new token: and\n",
      "current sentence length: 7,         new token: orders\n",
      "current sentence length: 8,         new token: a\n",
      "current sentence length: 9,         new token: beer\n",
      "current sentence length: 10,         new token: .\n",
      "current sentence length: 11,         new token: the\n",
      "current sentence length: 12,         new token: bartender\n",
      "current sentence length: 13,         new token: says\n",
      "current sentence length: 14,         new token: ,\n",
      "current sentence length: 15,         new token: you\n",
      "current sentence length: 16,         new token: know\n",
      "current sentence length: 17,         new token: ,\n",
      "current sentence length: 18,         new token: i\n",
      "current sentence length: 19,         new token: am\n",
      "current sentence length: 20,         new token: going\n",
      "current sentence length: 21,         new token: to\n",
      "current sentence length: 22,         new token: give\n",
      "current sentence length: 23,         new token: you\n",
      "current sentence length: 24,         new token: a\n",
      "current sentence length: 25,         new token: drink\n",
      "current sentence length: 26,         new token: .\n",
      "current sentence length: 27,         new token: ''\n",
      "current sentence length: 28,         new token: the\n",
      "current sentence length: 29,         new token: man\n",
      "current sentence length: 30,         new token: says\n",
      "current sentence length: 31,         new token: ,\n",
      "current sentence length: 32,         new token: well\n",
      "current sentence length: 33,         new token: ,\n",
      "current sentence length: 34,         new token: i\n",
      "current sentence length: 35,         new token: don't\n",
      "current sentence length: 36,         new token: know\n",
      "current sentence length: 37,         new token: ,\n",
      "current sentence length: 38,         new token: but\n",
      "current sentence length: 39,         new token: i\n",
      "current sentence length: 40,         new token: don't\n",
      "current sentence length: 41,         new token: have\n",
      "current sentence length: 42,         new token: any\n",
      "current sentence length: 43,         new token: trouble\n",
      "current sentence length: 44,         new token: .\n",
      "current sentence length: 45,         new token: the\n",
      "current sentence length: 46,         new token: bartender\n",
      "current sentence length: 47,         new token: replies\n",
      "current sentence length: 48,         new token: ,\n",
      "current sentence length: 49,         new token: i\n",
      "current sentence length: 50,         new token: just\n",
      "current sentence length: 51,         new token: got\n",
      "current sentence length: 52,         new token: a\n",
      "current sentence length: 53,         new token: beer\n",
      "current sentence length: 54,         new token: .\n"
     ]
    }
   ],
   "source": [
    "STARTER_SENTENCE=\"a man\"\n",
    "\n",
    "text2 = generate_text(target_score=5, generator=generator, model_config=model_config,\n",
    "                    tokenizer=tokenizer, starter_sentence=STARTER_SENTENCE,\n",
    "                    temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a man walks into a bar and orders a beer . the bartender says , you know , i am going to give you a drink . '' the man says , well , i don't know , but i don't have any trouble . the bartender replies , i just got a beer .\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sentence length: 2,         new token: walks\n",
      "current sentence length: 3,         new token: into\n",
      "current sentence length: 4,         new token: a\n",
      "current sentence length: 5,         new token: bar\n",
      "current sentence length: 6,         new token: and\n",
      "current sentence length: 7,         new token: takes\n",
      "current sentence length: 8,         new token: a\n",
      "current sentence length: 9,         new token: seat\n",
      "current sentence length: 10,         new token: to\n",
      "current sentence length: 11,         new token: the\n",
      "current sentence length: 12,         new token: bar\n",
      "current sentence length: 13,         new token: .\n",
      "current sentence length: 14,         new token: he\n",
      "current sentence length: 15,         new token: says\n",
      "current sentence length: 16,         new token: ,\n",
      "current sentence length: 17,         new token: i\n",
      "current sentence length: 18,         new token: don't\n",
      "current sentence length: 19,         new token: know\n",
      "current sentence length: 20,         new token: ,\n",
      "current sentence length: 21,         new token: but\n",
      "current sentence length: 22,         new token: i\n",
      "current sentence length: 23,         new token: have\n",
      "current sentence length: 24,         new token: no\n",
      "current sentence length: 25,         new token: idea\n",
      "current sentence length: 26,         new token: .\n",
      "current sentence length: 27,         new token: well\n",
      "current sentence length: 28,         new token: ,\n",
      "current sentence length: 29,         new token: i\n",
      "current sentence length: 30,         new token: don't\n",
      "current sentence length: 31,         new token: have\n",
      "current sentence length: 32,         new token: a\n",
      "current sentence length: 33,         new token: glass\n",
      "current sentence length: 34,         new token: of\n",
      "current sentence length: 35,         new token: my\n",
      "current sentence length: 36,         new token: way\n",
      "current sentence length: 37,         new token: .\n"
     ]
    }
   ],
   "source": [
    "STARTER_SENTENCE=\"a man\"\n",
    "\n",
    "text3 = generate_text(target_score=5, generator=generator, model_config=model_config,\n",
    "                    tokenizer=tokenizer, starter_sentence=STARTER_SENTENCE,\n",
    "                    temperature=0.5)\n",
    "text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sentence length: 2,         new token: is\n",
      "current sentence length: 3,         new token: sitting\n",
      "current sentence length: 4,         new token: on\n",
      "current sentence length: 5,         new token: a\n",
      "current sentence length: 6,         new token: plane\n",
      "current sentence length: 7,         new token: when\n",
      "current sentence length: 8,         new token: he\n",
      "current sentence length: 9,         new token: sees\n",
      "current sentence length: 10,         new token: a\n",
      "current sentence length: 11,         new token: man\n",
      "current sentence length: 12,         new token: in\n",
      "current sentence length: 13,         new token: the\n",
      "current sentence length: 14,         new token: front\n",
      "current sentence length: 15,         new token: porch\n",
      "current sentence length: 16,         new token: .\n",
      "current sentence length: 17,         new token: a\n",
      "current sentence length: 18,         new token: genie\n",
      "current sentence length: 19,         new token: appears\n",
      "current sentence length: 20,         new token: on\n",
      "current sentence length: 21,         new token: his\n",
      "current sentence length: 22,         new token: face\n",
      "current sentence length: 23,         new token: .\n",
      "current sentence length: 24,         new token: the\n",
      "current sentence length: 25,         new token: man\n",
      "current sentence length: 26,         new token: proceeds\n",
      "current sentence length: 27,         new token: to\n",
      "current sentence length: 28,         new token: his\n",
      "current sentence length: 29,         new token: wife\n",
      "current sentence length: 30,         new token: ,\n",
      "current sentence length: 31,         new token: and\n",
      "current sentence length: 32,         new token: the\n",
      "current sentence length: 33,         new token: man\n",
      "current sentence length: 34,         new token: asks\n",
      "current sentence length: 35,         new token: .\n",
      "current sentence length: 36,         new token: the\n",
      "current sentence length: 37,         new token: man\n",
      "current sentence length: 38,         new token: says\n",
      "current sentence length: 39,         new token: ,\n",
      "current sentence length: 40,         new token: oh\n",
      "current sentence length: 41,         new token: ,\n",
      "current sentence length: 42,         new token: i\n",
      "current sentence length: 43,         new token: have\n",
      "current sentence length: 44,         new token: a\n",
      "current sentence length: 45,         new token: problem\n",
      "current sentence length: 46,         new token: ,\n",
      "current sentence length: 47,         new token: i\n",
      "current sentence length: 48,         new token: have\n",
      "current sentence length: 49,         new token: a\n",
      "current sentence length: 50,         new token: few\n",
      "current sentence length: 51,         new token: of\n",
      "current sentence length: 52,         new token: my\n",
      "current sentence length: 53,         new token: penis\n",
      "current sentence length: 54,         new token: .\n",
      "current sentence length: 55,         new token: i\n",
      "current sentence length: 56,         new token: was\n",
      "current sentence length: 57,         new token: just\n",
      "current sentence length: 58,         new token: thinking\n",
      "current sentence length: 59,         new token: of\n",
      "current sentence length: 60,         new token: you\n",
      "current sentence length: 61,         new token: .\n",
      "current sentence length: 62,         new token: the\n",
      "current sentence length: 63,         new token: man\n",
      "current sentence length: 64,         new token: says\n",
      "current sentence length: 65,         new token: ,\n",
      "current sentence length: 66,         new token: you\n",
      "current sentence length: 67,         new token: have\n",
      "current sentence length: 68,         new token: a\n",
      "current sentence length: 69,         new token: question\n",
      "current sentence length: 70,         new token: ,\n",
      "current sentence length: 71,         new token: he\n",
      "current sentence length: 72,         new token: replies\n",
      "current sentence length: 73,         new token: ,\n",
      "current sentence length: 74,         new token: i\n",
      "current sentence length: 75,         new token: don't\n",
      "current sentence length: 76,         new token: know\n",
      "current sentence length: 77,         new token: ,\n",
      "current sentence length: 78,         new token: i\n",
      "current sentence length: 79,         new token: have\n",
      "current sentence length: 80,         new token: a\n",
      "current sentence length: 81,         new token: conversation\n",
      "current sentence length: 82,         new token: with\n",
      "current sentence length: 83,         new token: a\n",
      "current sentence length: 84,         new token: black\n",
      "current sentence length: 85,         new token: off\n",
      "current sentence length: 86,         new token: .\n"
     ]
    }
   ],
   "source": [
    "STARTER_SENTENCE=\"a man\"\n",
    "\n",
    "text4 = generate_text(target_score=10, generator=generator, model_config=model_config,\n",
    "                    tokenizer=tokenizer, starter_sentence=STARTER_SENTENCE,\n",
    "                    temperature=0.5)\n",
    "text4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
